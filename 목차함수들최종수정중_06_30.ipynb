{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf442da7",
   "metadata": {},
   "source": [
    "# library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d4c27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c7f28",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9429a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패턴을 이용하여 저장 값을 리스트로 되돌리는 함수\n",
    "def make_ls(c,i): # 인덱스 리스트와 순서를 받음\n",
    "    matches = re.findall(r\"'(.*?)'\", c[i])\n",
    "    return list(matches)\n",
    "\n",
    "def clear_text(sentence):  # 목차 내용 정제 함수\n",
    "    pattern = r'[\\w가-힣]+'\n",
    "    extracted = re.findall(pattern, sentence)\n",
    "    result = ' '.join(extracted)\n",
    "    return result\n",
    "    \n",
    "def delete_text(sentence):\n",
    "    pattern = r'u3000|u000|u00|uf0ab|u2005|'#목차 더보기'\n",
    "    result = re.sub(pattern, '', sentence)\n",
    "    return result\n",
    "    \n",
    "def split_pn(line,e): # 페이지 분리 함수\n",
    "    a = re.sub(r'[^(X|IX|IV|V?I|Ⅱ|Ⅲ)]','', line) # 로마자인지 구분하기 위함\n",
    "    if line.split(' ')[-1].isnumeric() == True and a == '':\n",
    "        page = line.split(' ')[-1]  \n",
    "        line = ' '.join(line.split(' ')[:-1])\n",
    "        k = 0\n",
    "        e = etc_check(e,page,k)\n",
    "    else:\n",
    "        page = np.NaN\n",
    "        k = 'pn'\n",
    "        e = etc_check(e,k)\n",
    "    \n",
    "    return line, page, e\n",
    "\n",
    "def plus_pandan(pd_l):\n",
    "    if '총' in pd_l and '각' in pd_l:\n",
    "        i = pd_l.index('총')\n",
    "        pd_l[i] = ['총', '각']\n",
    "        pd_l.remove('각')\n",
    "    elif '총론' in pd_l and '각론' in pd_l:\n",
    "        i = pd_l.index('총론')\n",
    "        pd_l[i] = ['총론', '각론']\n",
    "        pd_l.remove('각론')\n",
    "#     elif '총론' in pd_l and '각론' in pd_l and '부록' in pd_l:\n",
    "#         i = pd_l.index('총론')\n",
    "#         pd_l[i] = ['총론', '각론', '부록']\n",
    "    elif '형법총론' in pd_l and '형법각론' in pd_l:\n",
    "        i = pd_l.index('형법총론')\n",
    "        pd_l[i] = ['형법총론', '형법각론']\n",
    "        pd_l.remove('형법각론')\n",
    "    elif '헌법총론' in pd_l and '헌법각론' in pd_l:\n",
    "        i = pd_l.index('헌법총론')\n",
    "        pd_l[i] = ['헌법총론', '헌법각론']\n",
    "        pd_l.remove('헌법각론')\n",
    "    else:\n",
    "        pass\n",
    "    return pd_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eaafc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_list2(text, ex): # 판별 요소 설정 함수\n",
    "    pd_l,ck_l = [],[]\n",
    "    for idx, line in enumerate(text):\n",
    "        a = re.sub(r'[^(X|IX|IV|V?I|Ⅱ|Ⅲ)]','', line)  # r'(X|IX|IV|V?I|Ⅱ|Ⅲ) 이걸로 해보기\n",
    "        # 숫자 판별\n",
    "        if line[0].isnumeric() == True: \n",
    "            if a != '' and 'roma' not in pd_l: # 로마 숫자\n",
    "                ck_l.append('roma') # 위치 저장\n",
    "                pd_l.append('roma')\n",
    "            elif a != '' and 'roma' in pd_l: # 로마 숫자\n",
    "                ck_l.append('roma') # 위치 저장\n",
    "            elif a == '' and line[1] in ['부', '절','편','강'] and 'num' not in pd_l :\n",
    "                ck_l.append('num')\n",
    "                pd_l.append('num') # 분류랑 숫자 결합\n",
    "            elif a == '' and line[1] in ['부', '절','편','강'] and 'num' in pd_l:\n",
    "                ck_l.append('num')\n",
    "            elif a == '' and line[1] not in ['부', '절','편','강'] and 'ara' not in pd_l :\n",
    "                ck_l.append('ara')\n",
    "                pd_l.append('ara') # 분류랑 숫자 결합\n",
    "            elif a == '' and line[1] not in ['부', '절','편','강'] and 'ara' in pd_l:\n",
    "                ck_l.append('ara')\n",
    "        elif line[0].isnumeric() != True:   # 포함되는 리스트\n",
    "            t = re.sub(r'[^a-zA-Z가-힣]','',line.lower())  # 기록 시에는 line을 기록해야 함\n",
    "            b = ex.match(t)\n",
    "            if b and b.group() not in pd_l:\n",
    "                pd_l.append(b.group())\n",
    "                ck_l.append(b.group())\n",
    "            elif b and b.group() in pd_l:\n",
    "                ck_l.append(b.group())\n",
    "                pass\n",
    "            else:\n",
    "                pd_l.append('check')\n",
    "                \n",
    "    return pd_l, ck_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb42790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_idx(isbn, tit, text, i, ex):\n",
    "    code = isbn[i] # isbn, main_title\n",
    "    title = tit[i]\n",
    "#     d1,d2,d3,d4 = 0,0,0,0  # 뎁스 채울 변수(초기화)\n",
    "    if '목차 더보기' in text: # 잘못 들어간 단어 삭제(틀 전체로 접근하다 보니 같이 달려옴)\n",
    "        text.remove('목차 더보기')\n",
    "    text = [clear_text(r) for r in text] # 이상한 문자 제거\n",
    "    text = [delete_text(r) for r in text]\n",
    "    pandan,ck_l = classification_list2(text,ex)\n",
    "    print('iii')\n",
    "    e = pandan_sequence(pandan, ck_l)\n",
    "    print(e)\n",
    "    pandan = plus_pandan(pandan) \n",
    "    if 'check' in pandan:  # 분류구분자에 예외 표현이 존재\n",
    "        isbn_ls.append(code)\n",
    "        main_title.append(title)\n",
    "        etc.append('check')\n",
    "#         print('check')\n",
    "        for ls in [depth_1, depth_2, depth_3, depth_4, pages]:\n",
    "            ls.append(np.NaN)\n",
    "    elif 'check' not in pandan:\n",
    "        if len(pandan) == 1:\n",
    "#             print('len1')\n",
    "            for num, line in enumerate(text):\n",
    "                d,p,e = split_pn(line,e) ## tnwjd\n",
    "                depth_1.append(d)\n",
    "                depth_2.append(np.NaN)\n",
    "                depth_3.append(np.NaN)\n",
    "                depth_4.append(np.NaN)\n",
    "                etc.append(e) # 문제 없음\n",
    "                pages.append(p)\n",
    "                isbn_ls.append(code)\n",
    "                main_title.append(title)\n",
    "        elif len(pandan) == 2:\n",
    "            idx_plus(pandan, text, code, title, e)\n",
    "        elif len(pandan) == 3:\n",
    "            idx_plus(pandan, text, code, title, e)\n",
    "        elif len(pandan) >= 4:\n",
    "            idx_plus(pandan, text, code, title,e)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ef4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_plus(pandan, text, code, title,e):\n",
    "    d1,d2,d3,d4 = '','','',''\n",
    "    for num, line in enumerate(text):\n",
    "        a = re.sub(r'[^(Ⅹ|Ⅸ|Ⅳ|Ⅴ?Ⅰ|Ⅱ|Ⅲ)]','', line) \n",
    "        d,p,e = split_pn(line,e) #tnwjd\n",
    "        if d[0].isnumeric() == True and d[1] in ['부', '절','편','강']: # 숫자분류\n",
    "            check = 'num'\n",
    "        elif d[0].isnumeric() == True  and d[1] not in ['부', '절','편','강'] and a == '': # 아라비아\n",
    "            check = 'ara'\n",
    "        elif d[0].isnumeric() == True and a != '': # roma\n",
    "            check = 'roma'\n",
    "        elif d[0].isnumeric() != True:\n",
    "            base = re.sub(r'[^a-zA-Z가-힣]','',line.lower())\n",
    "            target = ex.match(base)\n",
    "            if target:\n",
    "                check = target.group()\n",
    "                if base.count(target.group())>1:\n",
    "                    k = 'over'\n",
    "                    e = etc_check(e,k)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        if type(pandan[0]) == list:\n",
    "            try:\n",
    "                ii = pandan.index(check)\n",
    "                if ii == 0:\n",
    "                    d1 = d\n",
    "                    d2,d3,d4 = '','',''\n",
    "                elif ii == 1:\n",
    "                    d2 = d\n",
    "                    d3,d4 = '',''\n",
    "                elif ii == 2:\n",
    "                    d3 = d\n",
    "                    d4 = ''\n",
    "                else:   # 4뎁스 이후꺼 삭제시 이걸로 조절\n",
    "                    d4 = d\n",
    "            except:\n",
    "                d1 = d\n",
    "            for ls in [0,1,2,3]:\n",
    "                d_append(ls,d1,d2,d3,d4)\n",
    "            etc.append(e)\n",
    "            pages.append(p)\n",
    "            isbn_ls.append(code)\n",
    "            main_title.append(title)\n",
    "            \n",
    "        elif type(pandan[1]) == list:  # 이부분 추가됨\n",
    "            try:\n",
    "                ii = pandan.index(check)\n",
    "                if ii == 0:\n",
    "                    d1 = d\n",
    "                    d2,d3,d4 = '','',''\n",
    "                elif ii == 1:\n",
    "                    d2 = d\n",
    "                    d3,d4 = '',''\n",
    "                elif ii == 2:\n",
    "                    d3 = d\n",
    "                    d4 = ''\n",
    "                else:   # 4뎁스 이후꺼 삭제시 이걸로 조절\n",
    "                    d4 = d\n",
    "            except:\n",
    "                d2 = d\n",
    "            for ls in [0,1,2,3]:\n",
    "                d_append(ls,d1,d2,d3,d4)\n",
    "            etc.append(e)\n",
    "            pages.append(p)\n",
    "            isbn_ls.append(code)\n",
    "            main_title.append(title)\n",
    "            \n",
    "        else:\n",
    "            print('store3')\n",
    "            ii = pandan.index(check)\n",
    "            ii = pandan.index(check)\n",
    "            if ii == 0:\n",
    "                d1 = d\n",
    "                d2,d3,d4 = '','',''\n",
    "            elif ii == 1:\n",
    "                d2 = d\n",
    "                d3,d4 = '',''\n",
    "            elif ii == 2:\n",
    "                d3 = d\n",
    "                d4 = ''\n",
    "            else:   # 4뎁스 이후꺼 삭제시 이걸로 조절\n",
    "                d4 = d\n",
    "            for ls in [0,1,2,3]:\n",
    "                d_append(ls,d1,d2,d3,d4)\n",
    "            etc.append(e)\n",
    "            pages.append(p)\n",
    "            isbn_ls.append(code)\n",
    "            main_title.append(title)\n",
    "        print(d1,d2,d3,d4,'store')\n",
    "#         store(pandan, check, d, p, code, title,d1,d2,d3,d4) # if_else문으로 check를 받고 시행하려고\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11a1b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_append(ls,d1,d2,d3,d4):\n",
    "    if ls == 0:\n",
    "        depth_dict[f'{ls}'].append(d1)\n",
    "    elif ls == 1:\n",
    "        depth_dict[f'{ls}'].append(d2)\n",
    "    elif ls == 2:\n",
    "        depth_dict[f'{ls}'].append(d3)\n",
    "    elif ls == 3:\n",
    "        depth_dict[f'{ls}'].append(d4)\n",
    "    print('d_append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f252cb",
   "metadata": {},
   "source": [
    "# making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af728ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_pandan(pd_l, ck_l):\n",
    "#     if len(pd_l) == 1:\n",
    "#         e = 0\n",
    "#     else:\n",
    "#         print('cp on')\n",
    "#         check = ''.join(ck_l).split(pd_l[0])\n",
    "#         pp = ''.join(pd_l[1:])\n",
    "#         if len(check) == 2:\n",
    "#             e = 0\n",
    "#         elif len(check) >= 3:\n",
    "#             if check[1][:len(pp)] == check[2][:len(pp)]:\n",
    "#                 e = 0 # 문제 없음\n",
    "#             elif check[1][:len(pp)] != check[2][:len(pp)]:\n",
    "#                 e = 'd_check'\n",
    "#             else:\n",
    "#                 e = 3 # 구분주려고 임시\n",
    "#                 print('???checkpandan')\n",
    "#         elif len(check) == 1:\n",
    "#             e = 2\n",
    "#         else:\n",
    "#             e = 3 # 구분주려고 임시\n",
    "#             print('??checkpandan')\n",
    "#     return e\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e137651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandan_sequence(pd_l, ck_l):\n",
    "    all_ls = ' '.join(ck_l).split(pd_l[0])\n",
    "    a_ls = []\n",
    "    print('pas')\n",
    "    for a in all_ls[1:]:\n",
    "    #     if c not in le:\n",
    "        x = []\n",
    "        for aa in a.split(' '):\n",
    "            if aa not in x:\n",
    "                x.append(aa)\n",
    "        a_ls.append(x)\n",
    "    if len(list(set(tuple(a) for a in a_ls))) > 1:\n",
    "        k = 'seq'\n",
    "        print('pas2')\n",
    "        e = etc_check(e, k)\n",
    "        print('pas333')\n",
    "    elif len(list(set(tuple(a) for a in a_ls))) == 1:\n",
    "        k = 0\n",
    "        e = etc_check(e, k)\n",
    "    else:\n",
    "        k = 0\n",
    "        e = etc_check(e, k)\n",
    "        print('????pandansequence')\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33bda555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'page_check'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_error['pn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f96b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etc_check(e, k):\n",
    "    print('etc')\n",
    "    if e == 0 and k != 0:\n",
    "        print('etc1')\n",
    "        e = dict_error[k]\n",
    "    elif e == 0 and k == 0:\n",
    "        e = 0\n",
    "    elif e != 0 and k == 0:\n",
    "        e = e\n",
    "    elif e != 0 and k != 0:\n",
    "        if e == 'double_check':\n",
    "            e = 'three_check'\n",
    "        else:\n",
    "            e = 'double_check'\n",
    "    print('etcs2')\n",
    "    return e\n",
    "    \n",
    "# for p in range(len(a)):\n",
    "#     if type(p) != float:\n",
    "#         if len(p) < 4:\n",
    "#             e = 0\n",
    "#         else:\n",
    "#             k = 'pn'\n",
    "#             e = etc_check(e, p, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b262fb3",
   "metadata": {},
   "source": [
    "# data loading & variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43859f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data  police_book_idx_unique\n",
    "data = pd.read_excel(\"C:\\police_data\\index_one_book.xlsx\")\n",
    "# 변수 설정\n",
    "isbn, tit, text = data['isbn'], data['main_title'], data['index']\n",
    "\n",
    "# 저장될 리스트\n",
    "isbn_ls, main_title, depth_1, depth_2, depth_3, depth_4, etc, pages = [],[],[],[],[],[],[],[]\n",
    "\n",
    "# depth정보를 저장할 변수\n",
    "d1,d2,d3,d4 = '','','',''\n",
    "# 구분자 리스트\n",
    "pandan = []\n",
    "# 구분자, 교재명\n",
    "check, title = '',''\n",
    "# isbn, 페이지\n",
    "code, p = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b563469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정 구분자\n",
    "ex = re.compile(\"제절|제편|제강|제항|제장|제회|제부|제과|제관|강|목|장|항|회|부|사례|총론|형법총론|헌법총론|각론|형법각론|헌법각론|부록|키워드|최근|실전|모의|문제|정답|해설|차례|전범위|기출|참고|판례|핵심|part|chapter|day|section|theme|case|keyword|point|q|question|contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ae344b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "pas2\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "iii\n",
      "pas\n",
      "pas2\n"
     ]
    }
   ],
   "source": [
    "# 편한 저장을 위해 딕셔너리\n",
    "depth_dict = {'0':depth_1,'1':depth_2,'2':depth_3,'3':depth_4}\n",
    "d_dict = {'0':d1,'1':d2,'2':d3,'3':d4} \n",
    "dict_error = {'pn':'page_check', 'over':'over_check','seq' : 'sequence_check'}\n",
    "# 실행\n",
    "for i in range(len(text)):\n",
    "    try:\n",
    "        tet = make_ls(text, i)\n",
    "        clear_idx(isbn, tit, tet, i, ex)\n",
    "    except:\n",
    "#         print('i')\n",
    "        isbn_ls.append(isbn[i])\n",
    "        main_title.append(tit[i])\n",
    "        etc.append(2)  # 데이터가 존재하지 않는 경우\n",
    "        for k in [depth_1, depth_2,depth_3,depth_4,pages]:\n",
    "            k.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd66e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 176)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_title), len(depth_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3fc33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ls = pd.DataFrame({'isbn':isbn_ls, 'main_title':main_title,'depth_1':depth_1, 'depth_2':depth_2,\\\n",
    "                      'depth_3':depth_3, 'depth_4': depth_4,'pages':pages,'etc':etc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a10741c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ls.to_excel('C:/police_data/06_30_test2.xlsx',encoding = 'utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad6eff76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ls.loc[:,'depth_2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bda6fae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>main_title</th>\n",
       "      <th>depth_1</th>\n",
       "      <th>depth_2</th>\n",
       "      <th>depth_3</th>\n",
       "      <th>depth_4</th>\n",
       "      <th>pages</th>\n",
       "      <th>etc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9791166184604</td>\n",
       "      <td>2023 경찰 헌법집중 기출해설</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9791197865367</td>\n",
       "      <td>한 권으로 끝내는 경찰범죄학(기본서)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9791169873437</td>\n",
       "      <td>박문각 경찰 박용증 아두스 경찰학 실전동형 10회분</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9791192989082</td>\n",
       "      <td>신간2024 최근 14년간 형사소송법 기출총정리</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9788952645432</td>\n",
       "      <td>2023 해양경찰 기관술(학) 기출문제집</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>9791166184871</td>\n",
       "      <td>경찰 헌법도약 기출지문 OX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>9791168809055</td>\n",
       "      <td>2023 해커스경찰 박철한 경찰헌법 실전동형모의고사</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>9791168809154</td>\n",
       "      <td>2023 해커스경찰 갓대환 형사법 진도별 문제풀이 1000제 1차 시험 대비</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>9791168808713</td>\n",
       "      <td>2023 해커스경찰 갓대환 형사법 기본서 1: 형법</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>9791168808720</td>\n",
       "      <td>2023 해커스경찰 갓대환 형사법 기본서 2: 형사소송법 수사와 증거</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              isbn                                  main_title  depth_1  \\\n",
       "0    9791166184604                           2023 경찰 헌법집중 기출해설      NaN   \n",
       "1    9791197865367                        한 권으로 끝내는 경찰범죄학(기본서)      NaN   \n",
       "2    9791169873437                박문각 경찰 박용증 아두스 경찰학 실전동형 10회분      NaN   \n",
       "3    9791192989082                  신간2024 최근 14년간 형사소송법 기출총정리      NaN   \n",
       "4    9788952645432                      2023 해양경찰 기관술(학) 기출문제집      NaN   \n",
       "..             ...                                         ...      ...   \n",
       "171  9791166184871                             경찰 헌법도약 기출지문 OX      NaN   \n",
       "172  9791168809055                2023 해커스경찰 박철한 경찰헌법 실전동형모의고사      NaN   \n",
       "173  9791168809154  2023 해커스경찰 갓대환 형사법 진도별 문제풀이 1000제 1차 시험 대비      NaN   \n",
       "174  9791168808713                2023 해커스경찰 갓대환 형사법 기본서 1: 형법      NaN   \n",
       "175  9791168808720      2023 해커스경찰 갓대환 형사법 기본서 2: 형사소송법 수사와 증거      NaN   \n",
       "\n",
       "     depth_2  depth_3  depth_4  pages  etc  \n",
       "0        NaN      NaN      NaN    NaN    2  \n",
       "1        NaN      NaN      NaN    NaN    2  \n",
       "2        NaN      NaN      NaN    NaN    2  \n",
       "3        NaN      NaN      NaN    NaN    2  \n",
       "4        NaN      NaN      NaN    NaN    2  \n",
       "..       ...      ...      ...    ...  ...  \n",
       "171      NaN      NaN      NaN    NaN    2  \n",
       "172      NaN      NaN      NaN    NaN    2  \n",
       "173      NaN      NaN      NaN    NaN    2  \n",
       "174      NaN      NaN      NaN    NaN    2  \n",
       "175      NaN      NaN      NaN    NaN    2  \n",
       "\n",
       "[176 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "226409f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m제항어쩌구저쩌구제항두번쨰\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# target = '제항'\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m text\u001b[38;5;241m.\u001b[39mcount(\u001b[43mtarget\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "text = '제항어쩌구저쩌구제항두번쨰'\n",
    "# target = '제항'\n",
    "text.count(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423dd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
